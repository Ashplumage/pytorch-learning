{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用pytorch实现ResNet  \n",
    "\n",
    "50行代码实现，这谁顶得住，开干开干"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现说明：\n",
    "\n",
    "1. 模型中存在大量的重复网络结构\n",
    "2. 对于模型中重复的部分，实现为子module或用函数生成对应的module\n",
    "3. 尽量使用nn.Seqential\n",
    "4. nn.Module和nn.Function结合使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch as t\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    '''\n",
    "    实现一个子模块\n",
    "    \n",
    "    '''\n",
    "    def __init__(self ,inchannel, outchannel, stride = 1, shortcut = None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, 3, stride, 1, bias = False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace= True),\n",
    "            nn.Conv2d(outchannel, outchannel, 3, 1, 1, bias = False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.right = shortcut\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        residual = x if self.right is None else self.right(x)\n",
    "        \n",
    "        out += residual\n",
    "        \n",
    "        return F.relu(out)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    '''\n",
    "        实现主module:ResNet34\n",
    "        ResNet34 包含多个layer, 每个layer又包含多个residual block\n",
    "        用子module实现residual block，用make_layer函数实现layer\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, num_class = 1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 7, 2, 3, bias = False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, 2, 1)\n",
    "        )\n",
    "        self.layer1 = self._make_layer(64, 128, 3)\n",
    "        self.layer2 = self._make_layer(128, 256, 4, stride = 2)\n",
    "        self.layer3 = self._make_layer(256, 512, 6, stride = 2 )\n",
    "        self.layer4 = self._make_layer(512, 512, 3, stride = 2)\n",
    "\n",
    "        self.fc = nn.Linear(512, num_class)\n",
    "\n",
    "    def _make_layer(self, inchannel, outchannel, block_num, stride =1 ):\n",
    "        '''\n",
    "        构建layer包含多个residual block\n",
    "        '''\n",
    "        shortcut = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, 1, stride, bias = False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(inchannel, outchannel, stride, shortcut))\n",
    "        \n",
    "        for i in range(1,block_num):\n",
    "            layers.append(ResidualBlock(outchannel, outchannel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.pre(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = F.avg_pool2d(x, 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        return self.fc(x)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block = ResidualBlock()\n",
    "model = ResNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = t.autograd.Variable(t.randn(1, 3, 224, 224))\n",
    "out = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (pre): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (right): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (right): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (right): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (right): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.0279e-01,  3.2270e-01, -2.1346e-01, -6.4585e-02, -1.2277e-01,\n",
       "          3.1704e-01, -2.6880e-01,  5.4051e-02,  6.3036e-01,  1.1401e-01,\n",
       "         -1.5322e-01,  2.5815e-02,  1.5689e-01, -6.7118e-02,  7.4015e-02,\n",
       "         -4.3403e-02,  9.7923e-02,  2.9348e-01, -1.9360e-01, -4.0967e-01,\n",
       "         -1.3117e-01, -9.6169e-02, -1.6637e-01,  4.5972e-01, -2.5299e-01,\n",
       "         -4.1093e-01,  2.6573e-01,  3.3544e-02,  2.2931e-01,  2.7117e-01,\n",
       "         -2.1993e-01, -2.2382e-01, -2.0749e-01,  1.0306e+00, -1.9673e-01,\n",
       "         -8.2401e-02, -3.1311e-01, -9.4969e-02,  5.4811e-01, -3.7894e-01,\n",
       "          2.1383e-01, -6.1764e-01, -3.4215e-01,  4.0260e-01, -6.2899e-01,\n",
       "         -9.2600e-02, -5.0489e-01, -7.1144e-01,  2.0432e-01, -2.5314e-01,\n",
       "         -2.0530e-01, -4.8832e-01,  5.9186e-01,  2.6577e-01, -8.3820e-02,\n",
       "         -9.7709e-02, -2.1208e-02, -2.0003e-01, -6.1839e-04, -5.2728e-01,\n",
       "          1.0948e-01, -3.1185e-01, -4.3275e-02,  1.6530e-02, -1.7877e-01,\n",
       "         -2.6744e-01,  9.8365e-02, -3.1777e-01,  1.0452e-01,  6.8409e-02,\n",
       "          2.3895e-01,  3.7713e-01, -4.1566e-01, -2.1269e-01,  2.2769e-01,\n",
       "         -1.5364e-02,  9.2304e-02,  1.5161e-01, -2.0739e-01,  1.2661e-01,\n",
       "         -4.1831e-02,  5.3107e-02, -3.2963e-01, -1.9490e-01,  3.6724e-01,\n",
       "          3.2124e-01, -3.0323e-01,  1.3287e-01,  1.3214e-02,  8.2333e-02,\n",
       "          2.1819e-01,  1.2505e-01, -4.4621e-01,  1.4541e-01, -5.5016e-01,\n",
       "         -8.4967e-02, -1.7902e-01,  4.7767e-01, -2.8498e-01, -5.8883e-01,\n",
       "         -6.0982e-02,  7.8942e-01,  7.5837e-01,  9.2188e-02,  6.4392e-01,\n",
       "         -5.8715e-01,  1.1224e-01, -3.3777e-01, -3.0347e-02, -3.9731e-01,\n",
       "         -2.1961e-01, -1.6577e-01,  1.1468e-01,  4.5956e-01, -2.5876e-02,\n",
       "          1.0326e-01, -5.0252e-01,  2.4426e-01,  1.3688e-02,  5.1049e-01,\n",
       "         -5.0982e-01,  2.7970e-02,  4.2315e-03, -6.3104e-02, -3.8365e-01,\n",
       "         -3.2847e-01,  3.5072e-01, -6.7081e-02,  5.0757e-02, -1.4334e-01,\n",
       "          6.1816e-02,  3.2749e-01,  4.3965e-01, -1.2968e-01, -5.5155e-02,\n",
       "          2.8439e-01,  1.6963e-01, -1.0861e-01, -2.0145e-01, -3.2208e-02,\n",
       "         -8.1934e-02,  3.8472e-01, -1.6679e-01,  8.0914e-02, -2.7859e-01,\n",
       "          7.7596e-01, -3.1260e-02,  3.2260e-01, -2.9276e-01, -1.0809e-01,\n",
       "          6.3053e-01, -9.1022e-04, -3.1023e-01,  5.8066e-02,  1.4467e-01,\n",
       "         -6.5948e-01,  1.8289e-01, -4.7367e-01, -4.4687e-02,  2.7812e-01,\n",
       "          2.4628e-01,  5.8133e-01, -8.5109e-02, -7.1543e-01, -5.7031e-01,\n",
       "          4.4571e-01,  2.8947e-01, -3.9713e-01,  4.4579e-02,  2.2319e-01,\n",
       "         -4.0771e-01,  4.5743e-01, -1.3043e-01, -2.2874e-01,  1.6485e-01,\n",
       "         -3.5567e-02, -2.1370e-01, -3.4382e-02,  5.3154e-01,  8.6295e-02,\n",
       "         -1.6473e-01,  1.0075e-01,  7.2507e-02,  2.0907e-01,  6.3728e-01,\n",
       "          2.1734e-02,  3.0374e-01, -7.5662e-01, -2.1401e-01,  4.1744e-01,\n",
       "          1.2655e-01, -7.5703e-02, -5.5892e-01, -7.9918e-02,  4.7754e-01,\n",
       "         -7.3477e-01,  2.0760e-01,  6.5798e-02, -6.4542e-01,  2.0523e-01,\n",
       "          6.7434e-02,  4.6949e-01,  2.7351e-01, -3.7240e-01,  5.6929e-01,\n",
       "         -2.3922e-01,  1.1394e-01,  4.2344e-01, -2.3325e-01, -2.3309e-02,\n",
       "          1.5567e-01, -2.2417e-01,  1.0180e-01, -5.5354e-01,  7.0975e-02,\n",
       "         -5.7167e-02,  2.2387e-01,  6.5613e-01,  3.7084e-02,  2.1020e-01,\n",
       "         -2.5563e-02, -1.5401e-01, -2.0219e-01,  3.5499e-01, -2.6706e-01,\n",
       "         -2.7301e-01,  2.8582e-01, -7.2503e-02, -3.9005e-01, -6.6600e-01,\n",
       "         -1.0791e-01,  6.2500e-02, -3.9075e-01,  7.6721e-01, -1.8404e-01,\n",
       "          2.1532e-01,  1.0956e-01, -7.9884e-01, -1.3534e-01,  6.6340e-01,\n",
       "         -5.0952e-02,  2.4834e-01,  2.6088e-01,  3.8095e-01,  1.7091e-01,\n",
       "          1.1112e-01,  3.5514e-01, -2.7130e-01, -4.0981e-02, -1.1886e-01,\n",
       "          4.4307e-01,  9.0951e-02,  3.1753e-01, -1.3576e-01,  3.5248e-01,\n",
       "          4.8134e-01,  8.0131e-02, -2.5155e-01,  3.3632e-01,  1.0073e-02,\n",
       "         -3.7518e-01,  8.9616e-01, -2.1280e-01,  2.0334e-01, -2.5797e-01,\n",
       "         -1.5136e-01, -9.2771e-02,  3.7123e-01, -3.3574e-01,  3.8258e-01,\n",
       "         -1.6921e-01, -7.5137e-03,  2.0596e-01, -3.6576e-01,  2.3206e-01,\n",
       "          4.7863e-02, -1.2510e-01, -3.0936e-01, -1.9498e-01,  5.5511e-01,\n",
       "         -2.0995e-01,  1.3284e-01,  1.8288e-01, -1.7100e-01, -6.0573e-01,\n",
       "         -3.9295e-01,  2.2743e-01, -9.0613e-02,  4.2149e-01,  3.5825e-02,\n",
       "         -1.4011e-01,  7.2183e-03,  1.6580e-01, -6.3971e-02, -1.0743e-01,\n",
       "          7.6747e-01,  4.8630e-01, -1.2615e-01, -6.4358e-01, -2.8333e-01,\n",
       "          6.2213e-02, -4.3086e-02, -5.0712e-01, -2.3420e-01,  1.0244e+00,\n",
       "          1.4662e-02,  4.9870e-02, -7.9023e-02,  9.3776e-02,  7.6611e-01,\n",
       "         -7.4100e-02, -3.8430e-01, -3.6395e-01,  6.6984e-02, -1.7551e-01,\n",
       "         -3.7055e-01,  3.2761e-02,  1.8830e-01,  3.7500e-02, -3.9732e-01,\n",
       "          9.5640e-02, -4.2614e-01,  1.1258e-01, -4.6234e-02,  2.9869e-01,\n",
       "          1.0616e-02,  7.3374e-02, -7.3980e-01, -2.4955e-02,  1.1526e-01,\n",
       "         -4.4155e-01, -4.5429e-01, -3.3741e-02,  4.3175e-02, -3.2018e-01,\n",
       "         -1.3941e-02,  2.3381e-01,  1.8335e-01, -8.8291e-01, -4.1927e-02,\n",
       "         -4.0102e-01, -5.2506e-02,  4.2988e-01,  1.7697e-02, -3.9394e-01,\n",
       "          8.5367e-02, -1.3453e-01,  3.3218e-02,  1.9178e-01,  3.1621e-01,\n",
       "         -3.4362e-01,  4.7031e-01,  7.2660e-01,  4.9465e-01,  4.1007e-01,\n",
       "          7.3704e-02,  2.6722e-02,  2.7730e-01, -1.7994e-01, -2.8555e-01,\n",
       "         -7.3081e-01, -5.2936e-01,  7.3040e-02,  4.7938e-01,  3.7566e-01,\n",
       "          2.5736e-01,  2.1478e-01,  2.4020e-01, -8.9441e-02, -4.0317e-01,\n",
       "          1.9790e-01, -4.5440e-01,  6.4162e-01, -3.3404e-01, -7.0133e-01,\n",
       "         -6.7247e-02,  2.3699e-03, -4.2559e-01, -5.2232e-01,  1.3522e-01,\n",
       "          4.0974e-01, -2.6599e-01, -6.4803e-02,  1.7341e-01, -1.1005e-01,\n",
       "          9.6163e-02,  6.9169e-01, -2.2241e-01, -6.4768e-01, -4.5915e-01,\n",
       "          1.5788e-01, -4.5581e-01,  1.1508e-01,  9.5330e-03,  1.0117e-01,\n",
       "          4.4392e-01, -3.5609e-01,  3.8163e-01, -4.1111e-02,  9.4491e-01,\n",
       "         -1.9519e-01, -7.8497e-02, -4.4939e-02, -3.1123e-01, -5.3896e-02,\n",
       "         -4.5721e-02,  3.1723e-01,  5.5455e-01,  1.2478e-01,  1.8219e-01,\n",
       "         -2.1068e-01, -3.5323e-01, -1.7454e-01, -2.3542e-01, -3.8606e-01,\n",
       "          2.1973e-02,  2.8234e-01, -6.8119e-01,  2.3125e-02,  2.5382e-01,\n",
       "          8.0345e-01,  4.4127e-01,  4.1713e-01, -7.7610e-02, -6.0605e-01,\n",
       "         -3.4823e-01,  6.0487e-01, -3.8273e-01, -3.3411e-01,  3.6227e-01,\n",
       "          2.1782e-01, -4.4708e-02, -1.4875e-01,  3.3008e-01,  5.8668e-01,\n",
       "         -2.3612e-01,  1.0370e-01, -7.0780e-02,  2.5522e-02,  2.5209e-01,\n",
       "         -5.8633e-02,  6.4087e-01,  8.2980e-01,  2.7483e-02,  4.9125e-01,\n",
       "          3.0091e-01,  1.1847e-01, -1.7006e-01,  1.5146e-01, -3.1577e-01,\n",
       "         -4.8977e-01,  8.0627e-01,  1.7223e-01,  4.4353e-01,  2.2418e-01,\n",
       "          4.1793e-03, -6.5114e-02, -5.8172e-03,  9.1330e-02, -2.3521e-01,\n",
       "         -1.8358e-01,  1.8092e-01,  1.4386e-02, -3.6003e-01, -3.3962e-01,\n",
       "         -5.0916e-02,  8.8664e-02, -3.3257e-01, -1.6385e-01,  3.7053e-01,\n",
       "          1.6238e-01, -2.2032e-01,  7.5901e-02, -1.2121e-01,  1.0782e-01,\n",
       "         -1.8235e-02,  2.8664e-01, -6.5414e-01,  4.0867e-01, -3.9269e-02,\n",
       "          4.3911e-01,  4.0407e-03,  2.7139e-01, -2.9346e-01, -7.2295e-01,\n",
       "         -6.2338e-01,  5.5598e-02,  2.0558e-01, -1.5322e-01, -2.9186e-01,\n",
       "         -1.0791e-01,  3.9441e-01, -1.7856e-01, -8.8010e-03,  1.9008e-01,\n",
       "          6.5456e-02, -3.5893e-01,  8.9283e-02,  1.3423e-01,  4.1420e-01,\n",
       "         -3.2538e-01,  1.8606e-01, -2.3640e-01, -4.3601e-01,  2.9691e-01,\n",
       "          1.5821e-01,  5.3637e-01, -3.6832e-02, -3.8652e-01, -5.3102e-01,\n",
       "          2.5146e-01,  3.1667e-01, -1.6508e-01,  6.5219e-02, -5.3526e-01,\n",
       "         -1.4927e-01, -2.8935e-01,  6.2368e-01,  4.7218e-02, -5.6706e-01,\n",
       "          2.0544e-01, -1.6236e-01, -1.5086e-01, -4.3696e-02, -1.0840e-01,\n",
       "         -4.6286e-01, -3.8573e-01,  8.3387e-02,  1.8666e-01,  2.1264e-02,\n",
       "         -6.0742e-02,  4.0098e-01,  3.2688e-01, -1.8094e-01,  1.8815e-01,\n",
       "          5.0509e-01, -4.1691e-01,  9.2657e-02,  1.5081e-02, -5.3226e-01,\n",
       "         -2.0570e-01, -8.4854e-02, -1.7644e-01,  4.3041e-01,  3.0636e-01,\n",
       "         -6.0346e-04,  8.2651e-03,  2.6227e-01, -1.1339e+00, -1.0345e-01,\n",
       "         -3.4053e-01,  2.5321e-01, -3.2352e-02, -4.0434e-01,  1.5225e-01,\n",
       "          4.6251e-01,  2.0381e-01,  1.8071e-01,  7.7199e-02, -3.2208e-01,\n",
       "         -4.3152e-01, -3.2905e-01,  3.3372e-01, -2.5692e-01,  3.4872e-01,\n",
       "          1.1521e-01, -1.9773e-01, -1.5627e-02,  4.0829e-03, -9.7946e-03,\n",
       "         -6.4877e-01, -6.4591e-02, -1.0511e+00,  1.2783e-01,  1.6467e-01,\n",
       "          1.3226e-02, -4.8070e-02, -4.3484e-01, -7.5162e-02,  2.1767e-01,\n",
       "         -3.2356e-01, -2.2819e-01,  7.0823e-01,  1.4233e-01, -5.5246e-01,\n",
       "         -1.8007e-02, -3.6713e-01,  2.8789e-01, -4.9919e-01,  3.0816e-01,\n",
       "          2.7480e-01, -1.9122e-01, -6.6081e-01,  2.8703e-01,  3.1386e-01,\n",
       "          2.6855e-01, -1.6387e-01, -4.0743e-01, -3.8815e-01, -3.8517e-01,\n",
       "         -1.2320e-01,  5.2075e-01, -2.3782e-01, -2.6230e-02,  2.1641e-01,\n",
       "          9.0038e-02,  1.6441e-02,  1.0175e-01, -2.5678e-01,  1.3974e-01,\n",
       "          2.1691e-01, -2.1852e-01,  4.2659e-02,  1.7200e-01, -1.3180e-02,\n",
       "         -3.5739e-01, -3.0961e-02,  2.3827e-01, -5.0867e-01,  5.7712e-01,\n",
       "          1.2770e-01,  8.8252e-02, -1.4703e-01,  5.3373e-01, -4.1292e-01,\n",
       "          8.5135e-01,  3.9552e-01, -6.1931e-01, -5.0679e-01,  6.0761e-02,\n",
       "          2.9927e-01,  2.6983e-01,  1.9729e-01,  3.3376e-01, -1.5345e-03,\n",
       "          2.2605e-01,  3.8423e-01, -2.7099e-01, -7.5490e-02,  2.7498e-01,\n",
       "         -7.8952e-01,  3.9944e-01, -5.5162e-01,  6.3558e-01, -2.3183e-01,\n",
       "         -6.7410e-01, -1.7770e-01, -1.4287e-01, -2.6723e-01, -5.1904e-01,\n",
       "          4.6838e-01, -6.7555e-02, -2.2434e-02, -2.0108e-01,  1.0446e-02,\n",
       "          8.7275e-02, -6.2560e-02,  5.2563e-01, -5.9747e-01, -3.5938e-01,\n",
       "          1.0201e-01, -1.0946e-01, -1.5225e-01, -1.7311e-01, -1.5997e-01,\n",
       "         -5.5187e-01,  7.0173e-02, -5.2620e-01, -1.6104e-01, -9.9010e-02,\n",
       "         -6.9840e-02, -8.1805e-03, -6.3392e-02, -3.3377e-01,  8.3524e-03,\n",
       "          5.1642e-02,  2.2634e-01,  1.7546e-02, -2.1660e-01,  7.5452e-01,\n",
       "          2.6497e-01, -2.6389e-01,  2.3093e-01, -4.7441e-01,  5.6994e-01,\n",
       "         -1.5142e-01, -5.0016e-01, -2.3215e-01,  1.3664e-01,  4.8374e-02,\n",
       "         -2.8359e-01,  4.5065e-02,  3.2524e-01, -2.2628e-01,  3.3082e-01,\n",
       "          2.8923e-01,  2.1489e-02, -1.6839e-01,  2.8260e-01,  1.5169e-02,\n",
       "          3.8825e-01,  5.0946e-01, -3.3145e-01,  1.6561e-02, -3.3040e-01,\n",
       "          5.2768e-01, -5.0368e-02,  2.5211e-01, -4.3323e-01, -5.8089e-01,\n",
       "          4.2173e-01,  7.3048e-01,  1.9980e-01,  7.4872e-02, -4.1111e-02,\n",
       "          5.6973e-02, -2.1033e-01,  4.2169e-01, -1.3271e-01,  2.3471e-01,\n",
       "          6.4910e-02,  1.9313e-02, -5.3914e-01, -3.4452e-01,  2.2315e-01,\n",
       "         -1.6950e-02,  4.4494e-01,  3.8969e-01,  7.7155e-02, -3.9040e-01,\n",
       "          7.3572e-02,  1.0697e-01, -2.2110e-01,  4.3505e-01, -2.2477e-01,\n",
       "          5.4090e-02,  3.6473e-01,  1.3326e-02,  2.3550e-02,  1.1375e-01,\n",
       "          4.7575e-02, -4.9659e-02,  2.2394e-01, -8.9764e-02, -2.4898e-01,\n",
       "         -2.6645e-01,  3.4727e-01, -1.9207e-02,  4.9919e-01, -1.6701e-01,\n",
       "         -2.6298e-01, -1.7924e-01,  8.1014e-02,  7.8195e-02,  1.7368e-01,\n",
       "          4.8911e-01,  2.5596e-01,  6.6735e-02, -2.6432e-01,  3.8139e-01,\n",
       "          9.0002e-01,  2.2460e-01,  1.2562e-01,  4.5899e-01, -2.8474e-01,\n",
       "          1.0281e-01,  2.3324e-01, -3.4362e-01, -1.4800e-01, -8.1572e-02,\n",
       "          2.8747e-01,  3.7764e-02, -3.3318e-01,  1.7923e-01,  4.2111e-03,\n",
       "          3.7358e-01, -4.6096e-01, -1.1776e-01, -1.9342e-01,  2.9787e-02,\n",
       "          3.2158e-01,  3.8151e-01, -6.1639e-01, -2.0712e-01,  4.9900e-01,\n",
       "         -1.8624e-01,  2.0092e-01,  1.3441e-01, -3.7511e-02,  7.0258e-01,\n",
       "          2.5791e-01,  2.0052e-02,  9.6341e-02, -5.8506e-02,  2.1443e-01,\n",
       "         -2.0176e-01, -3.0219e-01, -3.7772e-01, -7.1076e-02, -3.6983e-01,\n",
       "         -2.2964e-02, -7.8974e-02, -2.2782e-01, -4.4019e-01, -2.1486e-01,\n",
       "          3.9201e-01, -2.1491e-02, -6.0474e-01, -3.1819e-01,  4.6580e-01,\n",
       "         -6.3648e-01, -1.2090e-01,  1.2729e-03, -2.3118e-01,  3.9666e-02,\n",
       "         -3.0538e-02, -5.8376e-01,  5.7225e-02, -3.8473e-03, -3.7180e-01,\n",
       "          1.1701e-01, -3.0968e-01, -2.8940e-01, -2.2987e-02,  6.2063e-01,\n",
       "          2.4629e-01, -5.4264e-01, -1.3931e-01, -6.4156e-03,  1.7362e-01,\n",
       "          3.7473e-01,  4.4499e-03,  3.0396e-01,  2.0090e-02,  3.8905e-01,\n",
       "         -9.1795e-02,  7.1808e-02,  5.9315e-02,  1.7396e-02,  1.5414e-01,\n",
       "          2.4255e-01,  2.8559e-01, -1.9530e-02, -1.1525e-01,  1.2068e-01,\n",
       "         -2.4305e-01,  1.8911e-01,  4.7162e-01,  1.1422e-01,  3.5005e-01,\n",
       "          1.2116e-01,  5.0729e-01, -4.6935e-01,  2.0993e-01, -4.5827e-01,\n",
       "          3.2500e-01,  2.2818e-01,  2.1466e-01, -4.0281e-01, -6.2401e-01,\n",
       "          1.0985e-01, -9.6195e-02,  1.1888e-01,  3.4733e-01,  1.7014e-01,\n",
       "         -2.7673e-01, -3.8801e-02,  6.8322e-01, -1.1855e-01, -1.4482e-01,\n",
       "          4.2394e-02, -3.3412e-01, -1.2257e-02,  2.5927e-01,  2.7637e-01,\n",
       "         -2.4166e-01,  5.7322e-02,  7.3145e-01,  6.7038e-02, -6.3676e-01,\n",
       "          1.0288e-01, -4.9748e-01,  4.1035e-01, -2.3974e-01,  4.1087e-01,\n",
       "         -4.1571e-01, -4.7702e-01,  1.5277e-01,  5.7249e-01, -5.0143e-01,\n",
       "         -2.5840e-01, -4.1500e-01,  5.2589e-01,  3.1898e-01, -1.9641e-01,\n",
       "          3.6875e-01,  7.2150e-02,  2.1730e-01,  4.4798e-01, -2.2458e-01,\n",
       "          1.4188e-01, -1.3470e-01,  4.4249e-01,  3.3703e-01, -7.6981e-02,\n",
       "         -1.5268e-01, -3.5344e-01,  3.7697e-01, -1.8294e-01, -3.4567e-01,\n",
       "          3.6551e-01,  1.2164e-01,  4.3803e-02, -6.3681e-02, -1.4555e-01,\n",
       "         -3.2372e-01,  3.8879e-01,  7.5629e-02,  1.7998e-01, -1.8351e-03,\n",
       "          3.9946e-02,  1.0026e-01, -3.6627e-03,  2.6807e-01,  1.9309e-01,\n",
       "          3.7779e-01, -1.6664e-01, -2.1101e-01, -3.1132e-02,  9.9677e-02,\n",
       "         -1.1903e-01, -3.2946e-01,  5.7708e-01, -1.0896e-01, -2.1533e-01,\n",
       "          3.2805e-01,  3.3488e-01,  7.6222e-02, -3.0329e-01,  1.1373e-01,\n",
       "          3.4963e-02, -9.9570e-02,  3.5273e-01, -8.8029e-01, -2.4574e-01,\n",
       "         -1.3141e-01,  6.6807e-01,  4.2191e-01,  2.3279e-01, -1.3635e-01,\n",
       "          4.9989e-01, -2.3147e-01, -5.3404e-03, -1.6954e-01,  1.1508e-01,\n",
       "          1.9607e-02,  1.2107e-01, -4.8461e-02, -5.4457e-01,  2.8425e-01,\n",
       "         -6.6404e-02,  4.2071e-02,  2.5377e-02,  2.0134e-01, -1.8822e-01,\n",
       "          4.9818e-01,  1.1578e-01, -8.4122e-02,  2.5572e-01, -4.9926e-01,\n",
       "          5.1059e-02, -2.4407e-01, -1.0487e-01, -1.7539e-01,  1.8414e-02,\n",
       "         -6.5266e-01, -7.6689e-02,  2.8272e-01, -8.9743e-03,  9.1049e-02,\n",
       "          2.0577e-01, -2.8169e-01,  2.5671e-01,  3.3365e-01, -4.6281e-01,\n",
       "         -5.7017e-01,  9.5159e-02,  1.9763e-01,  4.8740e-01, -2.9559e-02,\n",
       "         -1.2915e-01, -2.0566e-01, -3.0278e-02, -4.9147e-01, -4.7628e-01,\n",
       "          1.9557e-01, -1.1116e-01,  8.5805e-02,  1.0031e-01, -3.9325e-01]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
